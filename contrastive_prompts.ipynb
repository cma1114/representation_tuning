{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Installs/imports\n",
    "#!pip install torch transformers datasets tabulate scikit-learn seaborn accelerate bitsandbytes\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from enhanced_hooking import get_activations, add_activations_and_generate, clear_hooks, get_activations_and_generate, zeroout_projections_and_generate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from enum import Enum\n",
    "class SteeringType(Enum):\n",
    "    IN_PROMPT = \"In prompt\"\n",
    "    CONTINUOUS = \"Continuous\"\n",
    "class AggType(Enum):\n",
    "    MEANDIFF = \"MeanDiff\"\n",
    "    PCA = \"PCA\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the model\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "model=None\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "base_model_path: str = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "model_path=base_model_path\n",
    "###model_path=\"cackerman/llama2_13b_chat_projection_tune_neg_in\"\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "_ = torch.set_grad_enabled(False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, token=HF_TOKEN, quantization_config=bnb_config, device_map=\"auto\")\n",
    "device = model.device\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path, token=HF_TOKEN)\n",
    "model.tokenizer = tokenizer\n",
    "if model.tokenizer.pad_token is None:\n",
    "    new_pad_token = model.tokenizer.eos_token\n",
    "    num_added_tokens = model.tokenizer.add_special_tokens({'pad_token': new_pad_token})\n",
    "    model.resize_token_embeddings(len(model.tokenizer))\n",
    "    model.config.pad_token_id = model.tokenizer.pad_token_id\n",
    "model_numlayers = model.config.num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in data\n",
    "\n",
    "outputdir = \"../output/\"\n",
    "datadir = \"../data/\"\n",
    "\n",
    "user_tag, asst_tag = \"[INST] \", \" [/INST]\"\n",
    "sys_tag_open, sys_tag_closed = \"<<SYS>> \", \" <</SYS>>\"\n",
    "model_numlayers = model.config.num_hidden_layers\n",
    "\n",
    "key_token_offset = 1###2\n",
    "pair_statement=False # pair labels\n",
    "test_on_gpt4facts=True\n",
    "\n",
    "strip_quotes = lambda s: s[1:-1] if len(s) > 1 and (s.startswith('\"') and s.endswith('\"') or s.startswith(\"'\") and s.endswith(\"'\")) else s\n",
    "\n",
    "### Contrastive prompts used to identify vectors ######\n",
    "pos_persona = \"Pretend that you are always honest, no matter what.\"\n",
    "neg_persona = \"Pretend that you are dishonest when it serves you.\"\n",
    "pos_label = \"A\"\n",
    "neg_label = \"B\"\n",
    "\n",
    "df = pd.read_csv(datadir+\"facts_true_false.csv\") #train\n",
    "true_statements = df[df['label'] == 1]['statement'].values.tolist()\n",
    "false_statements = df[df['label'] == 0]['statement'].values.tolist()\n",
    "\n",
    "def template(persona: str, stmt: str, label: str) -> str:\n",
    "    return f\"{user_tag}{sys_tag_open}{persona}{sys_tag_closed} Question: Is the following claim true or false? \\\"{strip_quotes(stmt)}\\\"\\n\\nChoices:\\n A) True\\n B) False\\n\\nAnswer:{asst_tag} {label}\"\n",
    "\n",
    "learn_directions_dataset = []\n",
    "if pair_statement:\n",
    "    for truth in true_statements:\n",
    "        learn_directions_dataset.append((template(pos_persona, truth, pos_label), template(neg_persona, truth, neg_label)))\n",
    "    for lie in false_statements:\n",
    "        learn_directions_dataset.append((template(pos_persona, lie, neg_label), template(neg_persona, lie, pos_label)))\n",
    "\n",
    "    letters_pos = np.array([\"T\" for _ in range(len(learn_directions_dataset)//2)] + [\"F\" for _ in range(len(learn_directions_dataset)//2)])\n",
    "    letters_neg = np.array([\"F\" for _ in range(len(learn_directions_dataset)//2)] + [\"T\" for _ in range(len(learn_directions_dataset)//2)])\n",
    "\n",
    "else:\n",
    "    for i, (truth, lie) in enumerate(zip(true_statements, false_statements)):#honest response always comes first in pair\n",
    "        learn_directions_dataset.append((template(pos_persona, truth, pos_label), template(neg_persona, lie, pos_label)))\n",
    "    for i, (truth, lie) in enumerate(zip(true_statements, false_statements)):# just to keep the letters ordering consistent\n",
    "        learn_directions_dataset.append((template(pos_persona, lie, neg_label), template(neg_persona, truth, neg_label)))\n",
    "\n",
    "    letters_pos = np.array([\"T\" for _ in range(len(learn_directions_dataset)//2)] + [\"F\" for _ in range(len(learn_directions_dataset)//2)])\n",
    "    letters_neg = np.array([\"T\" for _ in range(len(learn_directions_dataset)//2)] + [\"F\" for _ in range(len(learn_directions_dataset)//2)])\n",
    "\n",
    "print(len(learn_directions_dataset))\n",
    "for i in range(2):\n",
    "    print(f\"learn_directions_dataset[{i}]:\", *learn_directions_dataset[i])\n",
    "for i in range(len(learn_directions_dataset)-2, len(learn_directions_dataset)):\n",
    "    print(f\"learn_directions_dataset[{i}]:\", *learn_directions_dataset[i])\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get indexes where unsteered model gets it right\n",
    "\n",
    "cor_indexes = []\n",
    "sampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 1, \"do_sample\": False}\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "clear_hooks(model)\n",
    "model.eval()\n",
    "\n",
    "for i, (true_claim, false_claim) in enumerate(tqdm(learn_directions_dataset)):\n",
    "    if i == len(learn_directions_dataset)//2: break\n",
    "    input_text = true_claim[:-1].replace(f\"{sys_tag_closed}\",f\" Output only the letter corresponding to your choice.{sys_tag_closed}\")\n",
    "\n",
    "    inputs = model.tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    generated_tokens = model.generate(**inputs, **sampling_kwargs)\n",
    "    true_output = model.tokenizer.decode(generated_tokens[0][len(inputs['input_ids'][0]):],skip_special_tokens=True)\n",
    "\n",
    "    if true_output.lower() != \"a\": continue\n",
    "\n",
    "    input_text = false_claim[:-1].replace(f\"{sys_tag_closed}\",f\" Output only the letter corresponding to your choice.{sys_tag_closed}\")\n",
    "\n",
    "    inputs = model.tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    generated_tokens = model.generate(**inputs, **sampling_kwargs)\n",
    "    false_output = model.tokenizer.decode(generated_tokens[0][len(inputs['input_ids'][0]):],skip_special_tokens=True)\n",
    "    \n",
    "    if false_output.lower() in [\"b\"]: cor_indexes.append(i)\n",
    "\n",
    "print(cor_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_indexes = [0, 1, 4, 5, 6, 7, 8, 9, 11, 12, 14, 19, 21, 23, 24, 26, 28, 30, 33, 34, 38, 39, 41, 43, 45, 47, 48, 50, 51, 52, 53, 56, 57, 63, 64, 66, 67, 68, 69, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 88, 91, 92, 96, 97, 98, 100, 101, 105, 106, 108, 109, 111, 112, 114, 116, 118, 121, 122, 123, 124, 125, 128, 129, 130, 131, 133, 135, 138, 139, 141, 142, 143, 144, 145, 146, 150, 152, 153, 157, 158, 161, 162, 164, 165, 175, 179, 180, 182, 184, 185, 186, 188, 189, 190, 191, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 210, 211, 212, 214, 216, 218, 221, 223, 225, 227, 228, 232, 233, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 257, 258, 259, 261, 265, 267, 270, 272, 275, 276, 277, 278, 279, 280, 281, 282, 286, 287, 288, 290, 295, 296, 298, 299, 301, 304]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run contrastive prompts through model and capture activations\n",
    "\n",
    "steering_type = SteeringType.CONTINUOUS\n",
    "model.tokenizer.padding_side = \"right\"\n",
    "token_offsets = [0]\n",
    "key_token_offset = 1\n",
    "layers = range(model_numlayers)\n",
    "\n",
    "accumulated_activations_diffs = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "accumulated_activations_pos = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "accumulated_activations_neg = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "\n",
    "cor_indexes.extend([i + len(learn_directions_dataset)//2 for i in cor_indexes])\n",
    "\n",
    "learn_directions_dataset_cor = [learn_directions_dataset[i] for i in cor_indexes]\n",
    "learn_dataset = learn_directions_dataset_cor\n",
    "\n",
    "batch_size = 2\n",
    "batched_dataset = [\n",
    "(\n",
    "    [pair[0] for pair in learn_dataset[i:i + batch_size]],  # batch_pos\n",
    "    [pair[1] for pair in learn_dataset[i:i + batch_size]]  # batch_neg\n",
    ")\n",
    "for i in range(0, len(learn_dataset), batch_size)\n",
    "]\n",
    "\n",
    "for batch_pos, batch_neg in tqdm(batched_dataset, desc='Processing behavioral prompts'):\n",
    "    if steering_type == steering_type.IN_PROMPT:\n",
    "        batch_tokens_pos = []\n",
    "        batch_tokens_neg = []\n",
    "        for idx in range(len(batch_pos)):\n",
    "            tokens_pos = model.tokenizer.encode(batch_pos[idx], return_tensors=\"pt\")\n",
    "            tokens_neg = model.tokenizer.encode(batch_neg[idx], return_tensors=\"pt\")\n",
    "            if len(tokens_pos[0]) != len(tokens_neg[0]) and batch_neg[idx] != \"\": ##need to even out the lengths\n",
    "                appstr = \" \" * abs(len(tokens_neg[0]) - len(tokens_pos[0]))\n",
    "                apptok = model.tokenizer.encode(appstr, return_tensors=\"pt\")\n",
    "                if len(tokens_pos[0]) > len(tokens_neg[0]):\n",
    "                    tokens_neg = torch.cat((tokens_neg, apptok), dim=1)\n",
    "                else:\n",
    "                    tokens_pos = torch.cat((tokens_pos, apptok), dim=1)\n",
    "            batch_tokens_pos.append(tokens_pos)\n",
    "            batch_tokens_neg.append(tokens_neg)\n",
    "        batch_tokens_pos = torch.cat(batch_tokens_pos, dim=0)\n",
    "        batch_tokens_neg = torch.cat(batch_tokens_neg, dim=0)\n",
    "\n",
    "        get_at = add_at = \"start\"\n",
    "    else:\n",
    "        encoded_pos = model.tokenizer(batch_pos, return_tensors=\"pt\", padding=True)\n",
    "        encoded_neg = model.tokenizer(batch_neg, return_tensors=\"pt\", padding=True)\n",
    "        batch_tokens_pos = encoded_pos['input_ids']\n",
    "        batch_tokens_neg = encoded_neg['input_ids']\n",
    "        # Calculate the last/key_token_offset token position for each sequence in the batch\n",
    "        last_token_positions_pos = (encoded_pos['attention_mask'].sum(dim=1) - key_token_offset).tolist()\n",
    "        last_token_positions_neg = (encoded_neg['attention_mask'].sum(dim=1) - key_token_offset).tolist()\n",
    "\n",
    "        if min(last_token_positions_pos)<= (max(token_offsets) if token_offsets else priortoks+1) or min(last_token_positions_pos)<= (max(token_offsets) if token_offsets else priortoks+1):\n",
    "            print(\"input too short\")\n",
    "            continue\n",
    "\n",
    "        get_at = add_at = \"end\"\n",
    "\n",
    "    layers_positions = {}\n",
    "    for layer in layers:\n",
    "        if steering_type == \"In prompt\": layers_positions[layer] = [list(range(len(batch_tokens_pos[0]))) * len(batch_pos)] \n",
    "        else:\n",
    "            if token_offsets:\n",
    "                layers_positions[layer] = [[pos-i for i in token_offsets] for pos in last_token_positions_pos]\n",
    "            else:\n",
    "                layers_positions[layer] = [[pos-i for i in range(priortoks,-1,-1)] for pos in last_token_positions_pos] #[pos-2, pos-1, pos]\n",
    "\n",
    "    activations = get_activations(model, batch_tokens_pos, layers_positions, get_at=get_at) #returns a dictionary where keys are layers and values are dicts where keys are positions and values are batchsize d-embed tensors\n",
    "    for layer, positions in activations.items():\n",
    "        for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n",
    "            accumulated_activations_diffs[layer][pos] = torch.cat([accumulated_activations_diffs[layer][pos], tensor.clone()], dim=0)\n",
    "            accumulated_activations_pos[layer][pos] = torch.cat([accumulated_activations_pos[layer][pos], tensor], dim=0)\n",
    "\n",
    "    if len(batch_neg[0]) > 1:\n",
    "        layers_positions = {}\n",
    "        for layer in layers:\n",
    "            if steering_type == \"In prompt\": layers_positions[layer] = [list(range(len(batch_tokens_neg[0]))) * len(batch_pos)] \n",
    "            else:\n",
    "                if token_offsets:\n",
    "                    layers_positions[layer] = [[pos-i for i in token_offsets] for pos in last_token_positions_neg]\n",
    "                else:\n",
    "                    layers_positions[layer] = [[pos-i for i in range(priortoks,-1,-1)] for pos in last_token_positions_neg] #[pos-2, pos-1, pos]\n",
    "        activations = get_activations(model, batch_tokens_neg, layers_positions, get_at=get_at)\n",
    "        for layer, positions in activations.items():\n",
    "            for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n",
    "                accumulated_activations_neg[layer][pos] = torch.cat([accumulated_activations_neg[layer][pos], tensor], dim=0)\n",
    "                accumulated_activations_diffs[layer][pos][-len(batch_pos):] -= tensor\n",
    "\n",
    "meandiffs = {}\n",
    "for layer, positions in accumulated_activations_pos.items():\n",
    "    meandiffs[layer] = []\n",
    "    for pos in range(len(positions)):\n",
    "        meandiffs[layer].append(torch.mean((accumulated_activations_pos[layer][pos]-accumulated_activations_neg[layer][pos]), dim=0))\n",
    "normedmeandiffs = {}\n",
    "for layer, positions in meandiffs.items():\n",
    "    normedmeandiffs[layer] = []  \n",
    "    for pos in range(len(positions)):\n",
    "        normedmeandiffs[layer].append(meandiffs[layer][pos] / torch.norm(meandiffs[layer][pos], p=2, dim=0, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute direction vectors from activations to contrastive prompts\n",
    "\n",
    "agg_type = AggType.MEANDIFF#PCA#\n",
    "normvec = True\n",
    "use_raw = True\n",
    "\n",
    "def get_sign(activations_pos, activations_neg, direction): \n",
    "    #decide whether each direction vector is oriented such that \"honesty\" is high or low, based on a majority vote count of exemplar projections (ie, does the pos example in a pair tend to project higher or lower than the neg example)\n",
    "    projections_pos = (activations_pos @ direction) / torch.norm(direction)\n",
    "    projections_neg = (activations_neg @ direction) / torch.norm(direction)\n",
    "\n",
    "    positive_smaller_mean = np.mean(\n",
    "        [projections_pos[i] < projections_neg[i] for i in range(len(projections_pos))]\n",
    "    )\n",
    "    positive_larger_mean = np.mean(\n",
    "        [projections_pos[i] > projections_neg[i] for i in range(len(projections_pos))]\n",
    "    )\n",
    "    return -1 if positive_smaller_mean > positive_larger_mean else 1\n",
    "\n",
    "steering_vectors = {} #dictionary where keys are layers and values are lists of n_pos direction tensors\n",
    "if agg_type == AggType.MEANDIFF: #will also work for simple word/prefix substraction case as in the original steering activation post\n",
    "    steering_vectors = {}\n",
    "    \n",
    "    for layer, positions in accumulated_activations_pos.items():\n",
    "        steering_vectors[layer] = []\n",
    "        for pos in range(len(positions)):\n",
    "            steering_vectors[layer].append((accumulated_activations_pos[layer][pos]-accumulated_activations_neg[layer][pos]).mean(dim=0))\n",
    "            if normvec:\n",
    "                steering_vectors[layer][pos] /= torch.norm(steering_vectors[layer][pos], p=2, dim=0, keepdim=True)    \n",
    "    \"\"\"\n",
    "    for layer, positions in accumulated_activations_diffs.items():\n",
    "        steering_vectors[layer] = []\n",
    "        for pos in range(len(positions)):\n",
    "            steering_vectors[layer].append(torch.mean(accumulated_activations_diffs[layer][pos], dim=0))\n",
    "            if normvec:\n",
    "                steering_vectors[layer][pos] /= torch.norm(steering_vectors[layer][pos], p=2, dim=0, keepdim=True)  \n",
    "    \"\"\"\n",
    "elif agg_type == AggType.PCA: # get directions for each layer and position using PCA  \n",
    "    # takes second PC currently, but can take others or weight and combine  \n",
    "    if use_raw:\n",
    "        for layer, positions in accumulated_activations_pos.items():#dictionary where keys are layers and values are dicts where keys are positions and values are len(dataset) d-embed tensors\n",
    "            embeds = []\n",
    "            for pos in range(len(positions)):\n",
    "                activations_pos = accumulated_activations_pos[layer][pos]\n",
    "                activations_neg = accumulated_activations_neg[layer][pos]\n",
    "\n",
    "                activations = torch.cat([activations_pos, activations_neg], dim=0)\n",
    "                pca_model = PCA(n_components=2)\n",
    "                projected_activations = pca_model.fit_transform(activations)#[:,1]\n",
    "                coef1, coef2 = 0,1#pca_model.explained_variance_[0],pca_model.explained_variance_[1]\n",
    "                embeds.append(torch.from_numpy(pca_model.components_[0].astype(np.float32))*coef1/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[0].astype(np.float32))))\n",
    "                embeds[-1]+=torch.from_numpy(pca_model.components_[1].astype(np.float32))*coef2/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[1].astype(np.float32)))\n",
    "            steering_vectors[layer] = torch.stack(embeds)\n",
    "    else:\n",
    "        for layer, positions in accumulated_activations_diffs.items():#dictionary where keys are layers and values are dicts where keys are positions and values are len(dataset) d-embed tensors\n",
    "            embeds = []\n",
    "            for pos in range(len(positions)):\n",
    "                train = positions[pos] - positions[pos].mean(axis=0, keepdims=True)\n",
    "                pca_model = PCA(n_components=2, whiten=False).fit(train)\n",
    "                coef1, coef2 = 0,1#pca_model.explained_variance_[0],pca_model.explained_variance_[1]\n",
    "                embeds.append(torch.from_numpy(pca_model.components_[0].astype(np.float32))*coef1/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[0].astype(np.float32))))\n",
    "                embeds[-1]+=torch.from_numpy(pca_model.components_[1].astype(np.float32))*coef2/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[1].astype(np.float32)))\n",
    "            steering_vectors[layer] = torch.stack(embeds)            \n",
    "else: print(\"Unknown AGG_TYPE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save direction to file \n",
    "import pickle\n",
    "ofname = 'directions_llama3_8bchat_selfrec_hold_18keytokens_meandiff.pkl'\n",
    "with open(outputdir+ofname, 'wb') as f:\n",
    "    pickle.dump(steering_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take a look at how the components of the direction vectors are distributed\n",
    "\n",
    "def plot_activation_distribution(ax, activation, layer):\n",
    "    ax.hist(activation, bins=50, alpha=1.0)\n",
    "    ax.set_title(f'Distribution of Activations for Layer {layer}')\n",
    "    ax.set_xlabel('Activation Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "position = 9\n",
    "layers_to_show = list(range(model_numlayers))\n",
    "rows=(len(layers_to_show)-1)//3+1\n",
    "fig, axes = plt.subplots(rows, 3, figsize=(18, rows*5))\n",
    "for i, layer in enumerate(layers_to_show):\n",
    "    plot_activation_distribution(axes[i//3,i%3], nn_probes[layer][position], layer)\n",
    "#    plot_activation_distribution(axes[i//3,i%3], steering_vectors[layer][position], layer)\n",
    "#    plot_activation_distribution(axes[i//3,i%3], normedmeandiffs[layer][position], layer)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize differentiation of inputs by vectors: Binary classification: how often does the honest input have higher similarity to the \"honesty\" direction than the dishonest one does (by definition of the signs, if using training data this will be>=50%)\n",
    "\n",
    "layers = range(model_numlayers)\n",
    "position=0\n",
    "results = {layer: {} for layer in layers}\n",
    "\n",
    "direction_vector = steering_vectors[layer][position]\n",
    "\n",
    "for layer in layers:\n",
    "    sims_pos = (accumulated_activations_pos[layer][position] @ direction_vector) / (torch.norm(direction_vector)*torch.norm(accumulated_activations_pos[layer][position]))\n",
    "    sims_neg = (accumulated_activations_neg[layer][position] @ direction_vector) / (torch.norm(direction_vector)*torch.norm(accumulated_activations_neg[layer][position]))\n",
    "    sims = [[sims_pos[i],sims_neg[i]] for i in range(0, len(sims_pos))]\n",
    "    \n",
    "    cors = np.mean([max(S) == S[0] for S in sims])\n",
    "    \n",
    "    results[layer] = cors\n",
    "\n",
    "plt.plot(layers, [results[layer] for layer in layers], marker='o')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize differentiation: Plot mean projections/cosine sim between inputs and directions\n",
    "\n",
    "position = 4\n",
    "projections_honest={}\n",
    "projections_dishonest={}\n",
    "cos_sim=True\n",
    "\n",
    "direction_vector = steering_vectors[layer][position]\n",
    "\n",
    "for layer in layers:\n",
    "    pos_vec = accumulated_activations_pos[layer][position]\n",
    "    neg_vec = accumulated_activations_neg[layer][position]\n",
    "\n",
    "    projections_honest[layer] = (pos_vec @ direction_vector) / (torch.norm(direction_vector) * (torch.norm(pos_vec, dim=1, keepdim=True) if cos_sim else 1))\n",
    "    projections_dishonest[layer] = (neg_vec @ direction_vector) / (torch.norm(direction_vector) * (torch.norm(neg_vec, dim=1, keepdim=True) if cos_sim else 1))\n",
    "\n",
    "projections_honest_means = [torch.mean(projections_honest[layer]).item() for layer in layers] \n",
    "projections_dishonest_means = [torch.mean(projections_dishonest[layer]).item() for layer in layers]\n",
    "ylabel = 'Cosine Similarity to' if cos_sim else 'Projection onto'\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(layers, projections_honest_means, label='Selfrec', marker='o') \n",
    "plt.plot(layers, projections_dishonest_means, label='Neutral', marker='x')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel(f'Mean {ylabel} the \"Selfrec\" Direction')\n",
    "plt.title(f'Mean Input {ylabel} \"Selfrec\" Direction Across Layers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot input data projections onto vectors as scatterplots or histograms\n",
    " \n",
    "ans1=\"A\"#\"Y\"\n",
    "ans2=\"B\"#\"N\"\n",
    "\n",
    "def plot_projection(activations_pos, activations_neg, pc, ax, title, type):\n",
    "    \n",
    "    if type!=\"both\":\n",
    "        lbl = type.split(\"_\")[1]\n",
    "        activations_pos_projected = np.dot(activations_pos, pc)\n",
    "        activations_neg_projected = np.dot(activations_neg, pc)\n",
    "        ax.hist(activations_pos_projected, bins=50, alpha=0.5, label='+'+lbl)\n",
    "        ax.hist(activations_neg_projected, bins=50, alpha=0.5, label='-'+lbl)\n",
    "        ax.legend()\n",
    "\n",
    "    else:\n",
    "        activations_pos_projected = np.dot(activations_pos, pc.T)\n",
    "        activations_neg_projected = np.dot(activations_neg, pc.T)\n",
    "        for i, (x, y) in enumerate(activations_pos_projected):\n",
    "            if contrast_task:\n",
    "                if letters_selfrec[i] == ans1:#Say you wrote it\n",
    "                    ax.scatter(x, y, color=\"blue\", marker=\"o\", alpha=0.4)\n",
    "                elif letters_selfrec[i] == ans2:#Say you didn't write it\n",
    "                    ax.scatter(x, y, color=\"blue\", marker=\"x\", alpha=0.4)\n",
    "            else:\n",
    "                if letters_pos[i] == ans1:#True yes\n",
    "                    ax.scatter(x, y, color=\"blue\", marker=\"o\", alpha=0.4)\n",
    "                elif letters_pos[i] == ans2:#Rev no#False no\n",
    "                    ax.scatter(x, y, color=\"blue\", marker=\"x\", alpha=0.4)\n",
    "\n",
    "        for i, (x, y) in enumerate(activations_neg_projected):\n",
    "            if contrast_task:\n",
    "                if letters_neutral[i] == ans1:#Say it has neutral characteristic\n",
    "                    ax.scatter(x, y, color=\"red\", marker=\"o\", alpha=0.4)\n",
    "                elif letters_neutral[i] == ans2:#Say it doesn't have neutral characteristic\n",
    "                    ax.scatter(x, y, color=\"red\", marker=\"x\", alpha=0.4)\n",
    "            else:\n",
    "                if letters_neg[i] == ans1:#Rev yes#False yes\n",
    "                    ax.scatter(x, y, color=\"red\", marker=\"o\", alpha=0.4)\n",
    "                elif letters_neg[i] == ans2:#True no#False no\n",
    "                    ax.scatter(x, y, color=\"red\", marker=\"x\", alpha=0.4)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PC1' if \"pc2\" not in type else 'PC2')\n",
    "    if type==\"both\":\n",
    "      ax.legend(handles=[\n",
    "          plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label=f\"Pos {behavior} - {ans1}\"),\n",
    "          plt.Line2D([0], [0], marker='x', color='blue', markerfacecolor='blue', markersize=10, label=f\"Pos {behavior} - {ans2}\"),\n",
    "          plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label=f\"Neg {behavior} - {ans1}\"),\n",
    "          plt.Line2D([0], [0], marker='x', color='red', markerfacecolor='red', markersize=10, label=f\"Neg {behavior} - {ans2}\")\n",
    "      ])\n",
    "    else:\n",
    "      ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show PCA projections for every layer\n",
    "\n",
    "pcatype = \"raw\"\n",
    "position = 10#priortoks - 1\n",
    "cols = 3\n",
    "rows = (len(layers) - 1) // cols + 1\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, rows*5))\n",
    "for i, layer in enumerate(layers):\n",
    "    activations_pos = accumulated_activations_pos[layer][position]\n",
    "    activations_neg = accumulated_activations_neg[layer][position]\n",
    "    \n",
    "    if pcatype == \"raw\":\n",
    "        activations = torch.cat([activations_pos, activations_neg], dim=0)\n",
    "        pca_input = activations - activations.mean(axis=0, keepdims=True)\n",
    "    else:            \n",
    "        pca_input = accumulated_activations_diffs[layer][pos] - accumulated_activations_diffs[layer][pos].mean(axis=0, keepdims=True)\n",
    "    \n",
    "    pca_model = PCA(n_components=4, whiten=False).fit(pca_input)\n",
    "    pc1 = pca_model.components_[0] \n",
    "    pc2 = pca_model.components_[1] #steering_vectors[layer][position]#nn_probes[layer]#\n",
    "    print(pca_model.explained_variance_)\n",
    "    plot_projection(activations_pos, activations_neg, np.vstack((pc1, pc2)), axes[i // cols, i % cols], f\"{behavior}, layer {layer}\", type=\"both\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms of projections of activation data onto direction vector, across layers\n",
    "\n",
    "def plot_probe_projections(ax, probe, X_pos, X_neg, layer, position, bias=None):\n",
    "    X = torch.cat([X_pos, X_neg], dim=0)\n",
    "    y = torch.cat([torch.ones(X_pos.shape[0]), torch.zeros(X_neg.shape[0])])\n",
    "    projections = X @ probe + (bias if bias else 0)\n",
    "    \n",
    "    #ax.scatter(projections[y == 1], [1] * len(projections[y == 1]), color='blue', alpha=0.5, label='Behavior B (Pos)')\n",
    "    #ax.scatter(projections[y == 0], [0] * len(projections[y == 0]), color='red', alpha=0.5, label='Behavior B\\' (Neg)')\n",
    "    projections_pos = projections[y == 1].detach().numpy()\n",
    "    projections_neg = projections[y == 0].detach().numpy()\n",
    "    \n",
    "    # Calculate combined range for shared bins\n",
    "    min_value = min(projections_pos.min(), projections_neg.min())\n",
    "    max_value = max(projections_pos.max(), projections_neg.max())\n",
    "    bins = np.linspace(min_value, max_value, 20)\n",
    "    \n",
    "    ax.hist(projections_pos, bins=bins, alpha=0.5, label='Behavior B', color='blue')\n",
    "    ax.hist(projections_neg, bins=bins, alpha=0.5, label='Behavior B\\'', color='red')\n",
    "    ax.set_title(f'Histogram of Projections by Linear Probe for Layer {layer}, Position {position}')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Projection of Activations for Layer {layer}, Position {position}')\n",
    "    ax.set_xlabel('Projection Value')\n",
    "    ax.legend()\n",
    "\n",
    "position = 0\n",
    "\n",
    "cols = 3\n",
    "rows = (len(layers) - 1) // cols + 1\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, rows*5))\n",
    "for i, layer in enumerate(nn_probes):\n",
    "    direction_vector = nn_probes[layer]#nn_probes[layer][position]\n",
    "#    plot_probe_projections(axes[i // cols, i % cols], direction_vector, accumulated_activations_pos[layer][position], accumulated_activations_neg[layer][position], layer, position)\n",
    "    plot_probe_projections(axes[i // cols, i % cols], direction_vector, accumulated_activations_pos[layer][position][val_indices], accumulated_activations_neg[layer][position][val_indices], layer, position)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logit lens visualization of steering vector\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "position=5\n",
    "top_k = 10 \n",
    "mult=20\n",
    "colorscale = \"Reds\" if mult>=0 else \"Blues\"\n",
    "\n",
    "token_data = []\n",
    "probs_data = []\n",
    "\n",
    "for layer in range(model_numlayers):\n",
    "    vec=(mult*steering_vectors[layer][position]).to(device)\n",
    "#    vec=(mult*normedmeandiffs[layer][0]).to(device)\n",
    "    unembedded = model.lm_head(model.model.norm(vec.to(model.dtype)))\n",
    "    softmaxed = torch.nn.functional.softmax(unembedded, dim=-1)\n",
    "    values, indices = torch.topk(softmaxed, top_k)\n",
    "    probs_percent = [v for v in values.tolist()]\n",
    "    tokens = model.tokenizer.batch_decode(indices.unsqueeze(-1))\n",
    "    token_data.append(tokens)\n",
    "    probs_data.append(probs_percent) \n",
    "\n",
    "probs_array = np.array(probs_data)\n",
    "token_labels = np.array(token_data)\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans' \n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.heatmap(probs_array, annot=token_labels, fmt='', cmap=colorscale, xticklabels=False, yticklabels=[f\"Layer {l}\" for l in range(model_numlayers)])\n",
    "ax.set_title(f\"Logit Lens Top Token Probabilities at Multiplier {mult}\")\n",
    "ax.set_xlabel(f\"Top {top_k} Tokens\")\n",
    "\n",
    "# Adding a highlight for specific layers\n",
    "for layerlist in [[17,18]]:\n",
    "    rect = patches.Rectangle((0, layerlist[0]), top_k, len(layerlist), linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capture projections of inputs onto the behavioral direction vector during generation\n",
    "\n",
    "#import pickle\n",
    "#fname = 'directions_llama2_13b_f16_persona_lasttoken_pc2raw.pkl'\n",
    "#with open(outputdir+fname, 'rb') as f:\n",
    "#    steering_vectors = pickle.load(f)\n",
    "\n",
    "def cln(text):\n",
    "    return text.replace(pos_persona,\"\").replace(neg_persona,\"\").replace(\"  \",\" \")[:-2]\n",
    "lookback=19\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "sampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 2}\n",
    "\n",
    "directions = {layer: posvec[-1] for layer, posvec in steering_vectors.items()} # just look at final position vector for simplicity\n",
    "###directions = {layer: posvec[-1] for layer, posvec in fact_vectors.items()} # just look at final position vector for simplicity\n",
    "\n",
    "inputdata = [cln(x) for x, y in learn_directions_dataset] + [cln(y) for x, y in learn_directions_dataset] #first half honesty, second half dishonesty\n",
    "#inputdata = [x for x, y in learn_directions_dataset[:len(learn_directions_dataset)//2]] + [y for x, y in learn_directions_dataset[:len(learn_directions_dataset)//2]] + [x for x, y in learn_directions_dataset[len(learn_directions_dataset)//2:]] + [y for x, y in learn_directions_dataset[len(learn_directions_dataset)//2:]]#first half \"A\", second half \"B\"\n",
    "#inputdata = [x for x, y in learn_directions_dataset[:len(learn_directions_dataset)//2]] + [y for x, y in learn_directions_dataset[len(learn_directions_dataset)//2:]] + [y for x, y in learn_directions_dataset[:len(learn_directions_dataset)//2]] + [x for x, y in learn_directions_dataset[len(learn_directions_dataset)//2:]] #first half true facts, second half false facts\n",
    "#inputdata = [prompts_to_be_steered_tqa[i] for i in range(0,len(prompts_to_be_steered_tqa),2)] + [prompts_to_be_steered_tqa[i] for i in range(1,len(prompts_to_be_steered_tqa),2)]\n",
    "#inputdata = [gpt4facts_prompts[i] for j in range(0, len(gpt4facts_prompts)//10 , 2) for i in range(j*10, j*10+10)] + [gpt4facts_prompts[i] for j in range(1, len(gpt4facts_prompts)//10 , 2) for i in range(j*10, j*10+10)]\n",
    "\n",
    "\n",
    "layers = range(model_numlayers)\n",
    "\n",
    "accumulated_projections = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "\n",
    "batch_size=32\n",
    "batched_inputs = [\n",
    "        inputdata[p : p + batch_size] for p in range(0, len(inputdata), batch_size)\n",
    "    ]\n",
    "\n",
    "clear_hooks(model)\n",
    "model.to(device)\n",
    "for batch in tqdm(batched_inputs, desc='Generating projections'):\n",
    "    if prepend_bos: batch = [model.tokenizer.bos_token + input for input in batch]\n",
    "    inputs = model.tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    get_at = add_at = \"end\"\n",
    "\n",
    "    layers_positions = {}\n",
    "    for layer in layers:\n",
    "        layers_positions[layer] = [[len(inputs['input_ids'][pos])-offset for offset in range(lookback,0,-1)] for pos in range(len(inputs['input_ids']))]\n",
    "\n",
    "    activations = get_activations_and_generate(model, inputs, layers_positions, sampling_kwargs, get_at=get_at) #returns a dictionary where keys are layers and values are dicts where keys are positions and values are batchsize d-embed tensors\n",
    "    for layer, positions in activations.items():\n",
    "        for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n",
    "            projection = (tensor @ directions[layer].to(tensor.dtype)) / (torch.norm(directions[layer]) * torch.norm(tensor, dim=1))\n",
    "            accumulated_projections[layer][pos] = torch.cat([accumulated_projections[layer][pos], projection], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization: Heatamps out activation projections onto direction vectors across sequence positions and layers\n",
    "import seaborn as sns\n",
    "\n",
    "layers = list(range(len(accumulated_projections)))  \n",
    "positions = range(len(accumulated_projections[0])) \n",
    "offset=lookback\n",
    "split=len(accumulated_projections[0][0])//2\n",
    "data = np.zeros((len(layers), len(positions)))\n",
    "honest_mean_data = np.zeros((len(layers), len(positions)))\n",
    "dishonest_mean_data = np.zeros((len(layers), len(positions)))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    for j, position in enumerate(positions):\n",
    "        honest_mean_data[i, j] = torch.mean(accumulated_projections[layer][position][:split]).item()\n",
    "        dishonest_mean_data[i, j] = torch.mean(accumulated_projections[layer][position][split:]).item()\n",
    "        data[i, j] = honest_mean_data[i, j] - dishonest_mean_data[i, j]\n",
    "\n",
    "data_flipped = data[::-1, :] # Flip to show first layer at bottom\n",
    "\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "    \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_flipped, xticklabels=[p - offset for p in positions], yticklabels=sorted(layers,reverse=True), annot=False, cmap='coolwarm', vmin=-rmabs, vmax=rmabs)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Difference in Projections, Honesty - Dishonesty')\n",
    "plt.show()\n",
    "\n",
    "data_flipped = honest_mean_data[::-1, :] # Flip to show first layer at bottom\n",
    "\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_flipped, xticklabels=[p - offset for p in positions], yticklabels=sorted(layers,reverse=True), annot=False, cmap='coolwarm', vmin=-rmabs, vmax=rmabs)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Honesty Projections')\n",
    "plt.show()\n",
    "\n",
    "data_flipped = dishonest_mean_data[::-1, :] # Flip to show first layer at bottom\n",
    "\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_flipped, xticklabels=[p - offset for p in positions], yticklabels=sorted(layers,reverse=True), annot=False, cmap='coolwarm', vmin=-rmabs, vmax=rmabs)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Dishonesty Projections')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
